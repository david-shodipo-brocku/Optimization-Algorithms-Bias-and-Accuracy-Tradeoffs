{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be5abd05",
   "metadata": {},
   "source": [
    "# Annotated Code and Plain-English Results\n",
    "\n",
    "This file contains a line-by-line commented version of every code cell from your notebook, followed by a short, non-technical explanation of the results produced by those cells.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Libraries (setup)\n",
    "\n",
    "```python\n",
    "# Libraries\n",
    "# Install packages when running interactively (run once in a fresh environment)\n",
    "%pip install pandas numpy matplotlib seaborn scikit-learn\n",
    "\n",
    "# Import numerical and tabular data packages\n",
    "import numpy as np  # arrays, math helpers\n",
    "import pandas as pd  # tables / dataframes\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt  # plotting\n",
    "import seaborn as sns  # nicer plotting styles and helper functions\n",
    "```\n",
    "\n",
    "Explanation: Installs and imports the libraries used elsewhere. The `%pip install` line is for interactive notebooks only; the rest bring tools for data, math, and plotting.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Reproducibility\n",
    "\n",
    "```python\n",
    "# Reproducibility\n",
    "# Set a random seed so results are repeatable each run\n",
    "np.random.seed(2026) # To ensures the experiments produce consistent and reproducible results across runs.\n",
    "```\n",
    "\n",
    "Explanation: Fixes randomness so you get the same train/test split and other pseudo-random behavior every time.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: ucimlrepo install & import\n",
    "\n",
    "```python\n",
    "# Install dataset helper library (run once)\n",
    "%pip install ucimlrepo\n",
    "\n",
    "# To fetch datasets from the UCI Machine Learning Repository\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "```\n",
    "\n",
    "Explanation: Adds and imports a helper to download the UCI datasets used in the project.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Fetch Adult Income dataset\n",
    "\n",
    "```python\n",
    "# fetch dataset 1 : Adult Income dataset\n",
    "adult = fetch_ucirepo(id=2)  # download dataset with id 2 from ucimlrepo\n",
    "\n",
    "# Extract features and target\n",
    "X = adult.data.features # type: ignore  # feature table\n",
    "y = adult.data.targets # type: ignore   # target column or series\n",
    "\n",
    "# Combine features and target into a single DataFrame for easier manipulation\n",
    "data = pd.concat([X, y], axis=1)\n",
    "\n",
    "#Print dataframe\n",
    "display(data.head())  # show first rows\n",
    "print(\"Shape:\", data.shape)  # show (rows, cols)\n",
    "display(data.info())  # show column info and dtypes\n",
    "```\n",
    "\n",
    "Explanation: Downloads the Adult dataset, puts features and target together, and prints basic info so you can see what the data looks like.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Cleaning function for Adult dataset\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cleaning the data\n",
    "\n",
    "def clean_adult_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean the Adult Income dataset by standardizing strings,\n",
    "    handling missing values, fixing label formatting,\n",
    "    and removing duplicate records.\n",
    "    \"\"\"\n",
    "    # Work on a copy to avoid modifying the original DataFrame\n",
    "    df = df.copy()\n",
    "\n",
    "    # Identify all categorical (string) columns\n",
    "    categorical_cols = df.select_dtypes(include=\"object\").columns\n",
    "\n",
    "    # Strip leading/trailing whitespace from string columns\n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].str.strip()\n",
    "\n",
    "    # Convert Adult dataset's '?' placeholder to proper missing values\n",
    "    df = df.replace(\"?\", np.nan)\n",
    "\n",
    "    # Fix income labels in the test set (e.g., '>50K.' -> '>50K')\n",
    "    if \"income\" in df.columns:\n",
    "        df[\"income\"] = df[\"income\"].str.replace(\".\", \"\", regex=False)\n",
    "\n",
    "    # Remove exact duplicate rows\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    return df\n",
    "```\n",
    "\n",
    "Explanation: This function tidies string columns, replaces `?` with real missing values, normalizes income labels, and drops duplicate rows so the data is cleaner for modelling.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Apply cleaning and save\n",
    "\n",
    "```python\n",
    "data = clean_adult_df(data)  # run cleanup\n",
    "# Check for missing values\n",
    "display(data.isnull().sum().sort_values(ascending=False))  # show how many missing values per column\n",
    "\n",
    "# Also print to csv file\n",
    "data.to_csv('adult_income_dataset.csv', index=False)  # save cleaned dataset for later use\n",
    "```\n",
    "\n",
    "Explanation: Cleans the dataset, shows how many missing values remain, and saves a CSV copy.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Summary statistics\n",
    "\n",
    "```python\n",
    "# summary statistics\n",
    "summary_stats = data.describe()  # numeric summary: mean, std, quartiles\n",
    "summary_stats\n",
    "```\n",
    "\n",
    "Explanation: Gives a quick numeric summary of the dataset (counts, means, etc.). Useful to spot odd values or scale differences.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Define target and sensitive attribute\n",
    "\n",
    "```python\n",
    "# Extract target and sensitive attribute names\n",
    "if 'income' in data.columns:\n",
    "    target_col = 'income'\n",
    "else:\n",
    "    # fall back to last column if naming differs\n",
    "    target_col = data.columns[-1]\n",
    "\n",
    "# Map income to binary target\n",
    "y = (data[target_col].astype(str).str.strip() == \">50K\").astype(int)  # 1 for >50K, else 0\n",
    "X = data.drop(columns=[target_col])  # features only\n",
    "\n",
    "# Choose sensitive attribute (prefer 'sex', else try 'race')\n",
    "for cand in ['sex', 'race']:\n",
    "    if cand in X.columns:\n",
    "        sensitive_attr = cand\n",
    "        break\n",
    "else:\n",
    "    # if none of the common names exist, choose the first categorical column\n",
    "    cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    sensitive_attr = cat_cols[0] if cat_cols else None\n",
    "\n",
    "print('Target column:', target_col)\n",
    "print('Sensitive attribute chosen:', sensitive_attr)\n",
    "```\n",
    "\n",
    "Explanation: Builds the model target (0/1) from the income column, keeps features separate, and picks a protected attribute (`sex` or `race`) for fairness analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Train/test split and remove sensitive attribute from features\n",
    "\n",
    "```python\n",
    "# Train/test split with stratification to maintain class balance in both sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=2026\n",
    ")\n",
    "\n",
    "# Also extract sensitive attribute arrays for later group metrics\n",
    "A_train = X_train[sensitive_attr].copy() if sensitive_attr is not None else None\n",
    "A_test = X_test[sensitive_attr].copy() if sensitive_attr is not None else None\n",
    "\n",
    "# Remove sensitive attribute from features before modeling to prevent direct discrimination\n",
    "if sensitive_attr is not None:\n",
    "    X_train = X_train.drop(columns=[sensitive_attr])\n",
    "    X_test = X_test.drop(columns=[sensitive_attr])\n",
    "\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\n",
    "```\n",
    "\n",
    "Explanation: Splits the data into training and testing sets while keeping the class distribution the same, saves the sensitive attribute separately for fairness checks, and removes it from the inputs to avoid direct use in the model.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Preprocessing and baseline logistic regression (Adult)\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "# Separate numeric and categorical columns\n",
    "numeric_features = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "categorical_features = X_train.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "# Numeric transformer: fill missing values with median, then scale\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical transformer: fill missing with most frequent, then one-hot encode\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Column transformer applies the two transformers to their respective columns\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat\", categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# Full pipeline: preprocessing then logistic regression\n",
    "baseline_model = Pipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Fit baseline model\n",
    "baseline_model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "Explanation: Sets up standard preprocessing for numeric and categorical data, builds a pipeline with logistic regression, and trains the baseline model on the training set.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Evaluate Accuracy + AUC (Adult)\n",
    "\n",
    "```python\n",
    "y_pred = baseline_model.predict(X_test)  # predicted labels\n",
    "y_prob = baseline_model.predict_proba(X_test)[:, 1]  # predicted probabilities for positive class\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))  # fraction correct\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_prob))  # area under ROC curve\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))  # precision/recall per class\n",
    "```\n",
    "\n",
    "Explanation: Prints simple performance numbers: accuracy (how often the model is right) and AUC (how well it ranks positives vs negatives), plus a full classification report.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: ROC Curve (Adult)\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)  # false positive and true positive rates for thresholds\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc_score(y_test, y_prob):.3f}\")\n",
    "plt.plot([0,1], [0,1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Adult Baseline\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Explanation: Shows the ROC curve. The closer the curve is to the top-left, the better the model. The AUC number in the legend summarizes this as a single value.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Confusion matrix (Adult)\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)  # 2x2 matrix of counts\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix - Adult Baseline\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Explanation: Visual table of true/false positives/negatives. Useful to see the kinds of mistakes the model makes.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Demographic Parity - function\n",
    "\n",
    "```python\n",
    "def demographic_parity_diff(y_pred, A):\n",
    "    # Convert inputs to Series with fresh integer index\n",
    "    A = pd.Series(A).reset_index(drop=True)\n",
    "    y_pred = pd.Series(y_pred).reset_index(drop=True)\n",
    "\n",
    "    rates = {}\n",
    "    # For each group, compute positive prediction rate\n",
    "    for group in A.unique():\n",
    "        rates[group] = y_pred[A == group].mean()\n",
    "\n",
    "    # Return difference between highest and lowest positive rates and the rates dict\n",
    "    return max(rates.values()) - min(rates.values()), rates\n",
    "```\n",
    "\n",
    "Explanation: Computes how differently the model gives positive predictions across groups; a larger number means more disparity.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Compute and print Demographic Parity for Adult\n",
    "\n",
    "```python\n",
    "# Compute demographic parity difference and per-group positive rates\n",
    "\n",
    "dp_diff, dp_rates = demographic_parity_diff(y_pred, A_test)\n",
    "\n",
    "print(\"Demographic Parity Difference:\", dp_diff)\n",
    "print(\"Positive prediction rates by group:\", dp_rates)\n",
    "```\n",
    "\n",
    "Explanation: Shows the DP gap and the per-group rates so you can see which group gets more positive predictions.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Demographic Parity bar plot (Adult)\n",
    "\n",
    "```python\n",
    "dp_rates_series = pd.Series(dp_rates)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "dp_rates_series.plot(kind=\"bar\")\n",
    "plt.ylabel(\"Positive Prediction Rate\")\n",
    "plt.title(\"Demographic Parity - Positive Rates by Sex\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Explanation: A simple bar chart showing how the model's positive prediction rate varies by sex.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: (Adult) verbal note about gap\n",
    "\n",
    "```python\n",
    "# Large gap = more unfair\n",
    "# In this case, the demographic parity difference is 0.15,\n",
    "# which indicates that the model is more likely to predict a positive outcome for one group (males) compared to the other group (females).\n",
    "# This suggests that the model may be exhibiting bias against the group with the lower positive prediction rate,\n",
    "# and efforts to mitigate this disparity could be considered to improve fairness.\n",
    "```\n",
    "\n",
    "Explanation: A plain note interpreting the DP gap: 0.15 means one group gets positive predictions ~15% more often.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Equal Opportunity - function\n",
    "\n",
    "```python\n",
    "def equal_opportunity_diff(y_true, y_pred, A):\n",
    "    # Convert inputs to Series with fresh index\n",
    "    A = pd.Series(A).reset_index(drop=True)\n",
    "    y_true = pd.Series(y_true).reset_index(drop=True)\n",
    "    y_pred = pd.Series(y_pred).reset_index(drop=True)\n",
    "\n",
    "    tprs = {}\n",
    "    # For each group, compute true positive rate among actual positives\n",
    "    for group in A.unique():\n",
    "        idx = (A == group)\n",
    "        positives = (y_true[idx] == 1)\n",
    "        if positives.sum() > 0:\n",
    "            tprs[group] = (y_pred[idx][positives] == 1).mean()\n",
    "        else:\n",
    "            tprs[group] = np.nan\n",
    "\n",
    "    # Return the difference (max - min) and raw TPRs\n",
    "    return np.nanmax(list(tprs.values())) - np.nanmin(list(tprs.values())), tprs\n",
    "```\n",
    "\n",
    "Explanation: Computes TPR (sensitivity) per group and returns the gap. Smaller is better if fairness is the goal.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Compute and print Equal Opportunity (Adult)\n",
    "\n",
    "```python\n",
    "eo_diff, eo_tprs = equal_opportunity_diff(y_test, y_pred, A_test)\n",
    "\n",
    "print(\"Equal Opportunity Difference (TPR Gap):\", eo_diff)\n",
    "print(\"TPR by group:\", eo_tprs)\n",
    "```\n",
    "\n",
    "Explanation: Shows how TPR differs between groups. A non-zero gap means the model is better at finding positives for some groups than others.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Equal Opportunity bar plot (Adult)\n",
    "\n",
    "```python\n",
    "eo_tprs_series = pd.Series(eo_tprs)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "eo_tprs_series.plot(kind=\"bar\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Equal Opportunity - TPR by Sex\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Explanation: Bar chart visualizing the TPR per group so you can see whether bands are similar.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: (Adult) verbal note about TPR gap\n",
    "\n",
    "```python\n",
    "# Ideally bars should be similar height\n",
    "# In this case, the equal opportunity difference (TPR gap) is 0.10,\n",
    "# which indicates that the model has a higher true positive rate for one group (males) compared to the other group (females).\n",
    "```\n",
    "\n",
    "Explanation: A 0.10 gap means one group gets true positives about 10 percentage points more often.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Baseline results table (Adult)\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "results = {\n",
    "    \"dataset\": [\"Adult Income\"],\n",
    "    \"accuracy\": [accuracy_score(y_test, y_pred)],\n",
    "    \"auc\": [roc_auc_score(y_test, y_prob)],\n",
    "    \"dp_diff\": [dp_diff],\n",
    "    \"eo_diff\": [eo_diff]\n",
    "}\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)\n",
    "results_df.to_csv(\"baseline_results_adult.csv\", index=False)\n",
    "```\n",
    "\n",
    "Explanation: Collects key metrics into a table and saves them to `baseline_results_adult.csv` so you can compare later.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Fetch Heart Disease dataset\n",
    "\n",
    "```python\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Fetch dataset 2 : Heart Disease Dataset\n",
    "heart = fetch_ucirepo(id=45)\n",
    "\n",
    "# Extract features and target\n",
    "X_hd = heart.data.features # type: ignore\n",
    "y_hd = heart.data.targets # type: ignore\n",
    "\n",
    "# Combine into single dataframe\n",
    "data_hd = pd.concat([X_hd, y_hd], axis=1)\n",
    "\n",
    "# Display basic info\n",
    "display(data_hd.head())\n",
    "print(\"Shape:\", data_hd.shape)\n",
    "display(data_hd.info())\n",
    "```\n",
    "\n",
    "Explanation: Downloads and shows the heart disease dataset, similar to how the Adult data was handled.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Clean heart function\n",
    "\n",
    "```python\n",
    "# Cleaning the Heart Disease dataset\n",
    "\n",
    "def clean_heart_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    \"\"\"\n",
    "    Clean the Heart Disease dataset by standardizing strings,\n",
    "    handling missing values, and removing duplicates.\n",
    "    \"\"\"\n",
    "\n",
    "    # Work on a copy to avoid modifying the original DataFrame\n",
    "    df = df.copy()\n",
    "\n",
    "    # Replace '?' with NaN\n",
    "    df = df.replace(\"?\", np.nan)\n",
    "\n",
    "    # Convert numeric columns where possible (explicitly catch failures)\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Drop duplicate rows\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    return df\n",
    "```\n",
    "\n",
    "Explanation: Similar cleaning logic as the Adult dataset, plus attempts to convert numeric-looking columns to numeric dtype.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Apply heart cleaning and save\n",
    "\n",
    "```python\n",
    "data_hd = clean_heart_df(data_hd)\n",
    "# Check for missing values\n",
    "display(data_hd.isnull().sum().sort_values(ascending=False))\n",
    "\n",
    "# Also print to csv file\n",
    "data_hd.to_csv('heart_disease_dataset.csv', index=False)\n",
    "```\n",
    "\n",
    "Explanation: Cleans heart data, shows missing values, and saves a CSV.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Heart summary stats\n",
    "\n",
    "```python\n",
    "# summary statistics\n",
    "summary_stats = data_hd.describe()\n",
    "summary_stats\n",
    "```\n",
    "\n",
    "Explanation: Numeric summary of the heart dataset for quick checks.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Define heart target and sensitive attribute\n",
    "\n",
    "```python\n",
    "# Identify the target column (usually 'num' in UCI Heart Disease)\n",
    "if \"num\" in data_hd.columns:\n",
    "    target_col_hd = \"num\"\n",
    "else:\n",
    "    target_col_hd = data_hd.columns[-1]\n",
    "\n",
    "# Convert target to binary: 0 = no disease, 1 = disease (num > 0)\n",
    "y_hd = (pd.to_numeric(data_hd[target_col_hd], errors=\"coerce\") > 0).astype(int)\n",
    "\n",
    "# Features\n",
    "X_hd = data_hd.drop(columns=[target_col_hd])\n",
    "\n",
    "# Choose aensitive attribute (usually 'sex')\n",
    "sensitive_attr_hd = \"sex\" if \"sex\" in X_hd.columns else None\n",
    "\n",
    "print(\"Target column (Heart):\", target_col_hd)\n",
    "print(\"Sensitive attribute chosen (Heart):\", sensitive_attr_hd)\n",
    "```\n",
    "\n",
    "Explanation: Sets up the heart dataset target and chooses `sex` as the protected attribute if available.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Heart train/test split and remove sensitive attribute\n",
    "\n",
    "```python\n",
    "# Train/test split with stratification to maintain class balance in both sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_hd, X_test_hd, y_train_hd, y_test_hd = train_test_split(\n",
    "    X_hd, y_hd,\n",
    "    test_size=0.2,\n",
    "    stratify=y_hd,\n",
    "    random_state=2026,\n",
    ")\n",
    "\n",
    "# Save sensitive attribute for fairness metrics\n",
    "A_train_hd = X_train_hd[sensitive_attr_hd].copy() if sensitive_attr_hd else None\n",
    "A_test_hd  = X_test_hd[sensitive_attr_hd].copy() if sensitive_attr_hd else None\n",
    "\n",
    "# Remove sensitive attribute from model inputs\n",
    "if sensitive_attr_hd:\n",
    "    X_train_hd = X_train_hd.drop(columns=[sensitive_attr_hd])\n",
    "    X_test_hd  = X_test_hd.drop(columns=[sensitive_attr_hd])\n",
    "\n",
    "print(\"Train shape (Heart):\", X_train_hd.shape, \"Test shape (Heart):\", X_test_hd.shape)\n",
    "```\n",
    "\n",
    "Explanation: Same pattern as Adult: split, remember the sensitive attribute for fairness checks, and remove it from features.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Preprocessing and baseline logistic regression (Heart)\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Identify numeric vs categorical columns\n",
    "numeric_features_hd = X_train_hd.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "categorical_features_hd = X_train_hd.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "numeric_transformer_hd = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer_hd = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor_hd = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer_hd, numeric_features_hd),\n",
    "    (\"cat\", categorical_transformer_hd, categorical_features_hd)\n",
    "])\n",
    "\n",
    "baseline_model_hd = Pipeline([\n",
    "    (\"preprocess\", preprocessor_hd),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "baseline_model_hd.fit(X_train_hd, y_train_hd)\n",
    "```\n",
    "\n",
    "Explanation: Prepares and trains a logistic regression pipeline for the heart dataset, mirroring the Adult pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Evaluate Heart Accuracy + AUC\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "y_pred_hd = baseline_model_hd.predict(X_test_hd)\n",
    "y_prob_hd = baseline_model_hd.predict_proba(X_test_hd)[:, 1]\n",
    "\n",
    "print(\"Heart Accuracy:\", accuracy_score(y_test_hd, y_pred_hd))\n",
    "print(\"Heart AUC:\", roc_auc_score(y_test_hd, y_prob_hd))\n",
    "print(\"\\nHeart Classification Report:\\n\", classification_report(y_test_hd, y_pred_hd))\n",
    "```\n",
    "\n",
    "Explanation: Prints performance numbers for the heart model (accuracy, AUC, and class-wise metrics).\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Heart ROC Curve\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr_hd, tpr_hd, _ = roc_curve(y_test_hd, y_prob_hd)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr_hd, tpr_hd, label=f\"AUC = {roc_auc_score(y_test_hd, y_prob_hd):.3f}\")\n",
    "plt.plot([0,1], [0,1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Heart Disease Baseline\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Explanation: ROC plot for the heart model; AUC in legend summarizes performance.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Heart confusion matrix\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm_hd = confusion_matrix(y_test_hd, y_pred_hd)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm_hd, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix - Heart Disease Baseline\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Explanation: Shows counts of true/false positives/negatives for the heart model.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Demographic parity (Heart)\n",
    "\n",
    "```python\n",
    "# Reuse demographic_parity_diff defined earlier\n",
    "\n",
    "dp_diff_hd, dp_rates_hd = demographic_parity_diff(y_pred_hd, A_test_hd)\n",
    "\n",
    "print(\"Heart Demographic Parity Difference:\", dp_diff_hd)\n",
    "print(\"Heart Positive prediction rates by group:\", dp_rates_hd)\n",
    "```\n",
    "\n",
    "Explanation: Computes DP gap for the heart dataset and prints the per-group positive rates.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Demographic parity plot (Heart)\n",
    "\n",
    "```python\n",
    "dp_rates_hd_series = pd.Series(dp_rates_hd)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "dp_rates_hd_series.plot(kind=\"bar\")\n",
    "plt.ylabel(\"Positive Prediction Rate\")\n",
    "plt.title(\"Demographic Parity - Positive Rates by Sex (Heart)\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Explanation: Bar chart showing positive prediction rates for groups in the heart dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: (Heart) verbal note about DP gap\n",
    "\n",
    "```python\n",
    "# Large gap = more unfair\n",
    "# In this case, the demographic parity difference is 0.20,\n",
    "# which indicates that the model is more likely to predict a positive outcome for one group (males) compared to the other group (females).\n",
    "# This suggests that the model may be exhibiting bias against the group with the lower positive prediction rate,\n",
    "# and efforts to mitigate this disparity could be considered to improve fairness.\n",
    "```\n",
    "\n",
    "Explanation: Interprets the DP gap in plain language.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Equal Opportunity (Heart)\n",
    "\n",
    "```python\n",
    "eo_diff_hd, eo_tprs_hd = equal_opportunity_diff(y_test_hd, y_pred_hd, A_test_hd)\n",
    "\n",
    "print(\"Heart Equal Opportunity Difference (TPR Gap):\", eo_diff_hd)\n",
    "print(\"Heart TPR by group:\", eo_tprs_hd)\n",
    "```\n",
    "\n",
    "Explanation: Computes and prints the TPR gap for the heart dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Equal Opportunity plot (Heart)\n",
    "\n",
    "```python\n",
    "eo_tprs_hd_series = pd.Series(eo_tprs_hd)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "eo_tprs_hd_series.plot(kind=\"bar\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Equal Opportunity - TPR by Sex (Heart)\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Explanation: Shows TPR by group for the heart dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: (Heart) verbal note about TPR gap\n",
    "\n",
    "```python\n",
    "# Ideally bars should be similar height\n",
    "# In this case, the equal opportunity difference (TPR gap) is 0.10,\n",
    "# which indicates that the model has a higher true positive rate for one group (males) compared to the other\n",
    "```\n",
    "\n",
    "Explanation: A short note: a 0.10 TPR gap means some imbalance in true positive detection across groups.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Heart baseline results table\n",
    "\n",
    "```python\n",
    "results_hd = {\n",
    "    \"dataset\": [\"Heart Disease\"],\n",
    "    \"accuracy\": [accuracy_score(y_test_hd, y_pred_hd)],\n",
    "    \"auc\": [roc_auc_score(y_test_hd, y_prob_hd)],\n",
    "    \"dp_diff\": [dp_diff_hd],\n",
    "    \"eo_diff\": [eo_diff_hd]\n",
    "}\n",
    "\n",
    "results_hd_df = pd.DataFrame(results_hd)\n",
    "display(results_hd_df)\n",
    "results_hd_df.to_csv(\"baseline_results_heart.csv\", index=False)\n",
    "```\n",
    "\n",
    "Explanation: Collects heart metrics into a table and saves them for comparison.\n",
    "\n",
    "---\n",
    "\n",
    "### Cell: Combined results (Adult + Heart)\n",
    "\n",
    "```python\n",
    "# Combine Adult + Heart into one table\n",
    "combined_results_df = pd.concat([results_df, results_hd_df], ignore_index=True)\n",
    "display(combined_results_df)\n",
    "\n",
    "combined_results_df.to_csv(\"baseline_results_combined.csv\", index=False)\n",
    "```\n",
    "\n",
    "Explanation: Puts both datasets' baseline metrics side-by-side and saves to CSV for convenience.\n",
    "\n",
    "---\n",
    "\n",
    "# Quick plain-English summary of all results\n",
    "\n",
    "- **Accuracy**: shows how often the model got the label right. Higher is better for simple performance.\n",
    "- **AUC**: shows overall ranking ability; closer to 1 is better.\n",
    "- **Demographic Parity Difference (dp_diff)**: how differently the model gives positive outcomes across protected groups. Lower is fairer (0 is perfectly equal).\n",
    "- **Equal Opportunity Difference (eo_diff)**: the gap in true positive rate across groups. Lower is fairer for detecting actual positives equally.\n",
    "\n",
    "If you want, I can now:\n",
    "\n",
    "- Insert these commented code blocks directly into the notebook cells, replacing the original code (in-place), or\n",
    "- Keep this annotated markdown file and optionally commit/save it, or\n",
    "- Produce a cleaned PDF or share a shorter summary slide with the plain-language results.\n",
    "\n",
    "Tell me which of the three you prefer and I'll continue."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
